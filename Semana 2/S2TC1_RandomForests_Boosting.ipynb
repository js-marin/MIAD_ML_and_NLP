{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir si el precio del automóvil es alto o no. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "7    2014     6480        0           0            0         1          0   \n",
       "11   2014    39972        0           0            0         0          1   \n",
       "167  2016    18989        0           0            0         0          0   \n",
       "225  2014    51330        0           0            0         1          0   \n",
       "270  2007   116065        0           1            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "7            0           0          1  \n",
       "11           0           0          0  \n",
       "167          1           0          1  \n",
       "225          0           0          0  \n",
       "270          0           0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el acurracy del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1\n",
    "\n",
    "#Calculo gini\n",
    "\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimacion gini iputity parar evaluar cada particion\n",
    "\n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5778472913408218,\n",
       " 'level': 0,\n",
       " 'split': [1, 51394.909090909096],\n",
       " 'n_samples': 7031,\n",
       " 'gain': 0.23630504821132137,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8375781948168007,\n",
       "  'level': 1,\n",
       "  'split': [0, 2015.0],\n",
       "  'n_samples': 4474,\n",
       "  'gain': 0.03713896892744761,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 0.6404416839199448,\n",
       "   'level': 2,\n",
       "   'split': [0, 2013.0],\n",
       "   'n_samples': 1447,\n",
       "   'gain': 0.043426293133466354,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.2780487804878049,\n",
       "    'level': 3,\n",
       "    'split': [0, 2012.0],\n",
       "    'n_samples': 203,\n",
       "    'gain': 0.05394731382546758,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.09195402298850575,\n",
       "     'level': 4,\n",
       "     'split': [1, 35652.36363636363],\n",
       "     'n_samples': 85,\n",
       "     'gain': 0.01352946029496721,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.24,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 23,\n",
       "      'gain': 0.08132745221592097,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.15,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 18,\n",
       "       'gain': 0.08641975308641975},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.5714285714285714,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 5,\n",
       "       'gain': 0.21333333333333332}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.046875,\n",
       "      'level': 5,\n",
       "      'split': [1, 50471.36363636364],\n",
       "      'n_samples': 62,\n",
       "      'gain': 0.0038712154997273124,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.034482758620689655,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 56,\n",
       "       'gain': 0.0023384353741496555},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.25,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 6,\n",
       "       'gain': 0.11111111111111102}}},\n",
       "    'sr': {'y_pred': 0,\n",
       "     'y_prob': 0.4166666666666667,\n",
       "     'level': 4,\n",
       "     'split': [1, 24887.363636363636],\n",
       "     'n_samples': 118,\n",
       "     'gain': 0.020017026523643233,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.6923076923076923,\n",
       "      'level': 5,\n",
       "      'split': [6, 0.2727272727272734],\n",
       "      'n_samples': 11,\n",
       "      'gain': 0.11639118457300279,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 8,\n",
       "       'gain': 0.05208333333333334},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.4,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 3,\n",
       "       'gain': 0.4444444444444444}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.3853211009174312,\n",
       "      'level': 5,\n",
       "      'split': [8, 0.36363636363637397],\n",
       "      'n_samples': 107,\n",
       "      'gain': 0.02069617568904858,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.35353535353535354,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 97,\n",
       "       'gain': 0.01725661384576438},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6666666666666666,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 10,\n",
       "       'gain': 0.18000000000000005}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.6998394863563403,\n",
       "    'level': 3,\n",
       "    'split': [1, 39822.0],\n",
       "    'n_samples': 1244,\n",
       "    'gain': 0.024256063237019176,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 0.7671081677704195,\n",
       "     'level': 4,\n",
       "     'split': [6, 1.0],\n",
       "     'n_samples': 904,\n",
       "     'gain': 0.014011200973446158,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.8110014104372355,\n",
       "      'level': 5,\n",
       "      'split': [1, 37595.63636363637],\n",
       "      'n_samples': 707,\n",
       "      'gain': 0.00556156034847427,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.827639751552795,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 642,\n",
       "       'gain': 0.0036738773886121345},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6417910447761194,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 65,\n",
       "       'gain': 0.014700508668119894}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.6080402010050251,\n",
       "      'level': 5,\n",
       "      'split': [1, 25090.727272727276],\n",
       "      'n_samples': 197,\n",
       "      'gain': 0.0509520357534477,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8108108108108109,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 72,\n",
       "       'gain': 0.013111348528015265},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.4881889763779528,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 125,\n",
       "       'gain': 0.010412280112044925}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.52046783625731,\n",
       "     'level': 4,\n",
       "     'split': [6, 1.0],\n",
       "     'n_samples': 340,\n",
       "     'gain': 0.05453490718936188,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.6098484848484849,\n",
       "      'level': 5,\n",
       "      'split': [8, 1.0],\n",
       "      'n_samples': 262,\n",
       "      'gain': 0.016551370145274913,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.5714285714285714,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 222,\n",
       "       'gain': 0.016980819925555668},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.8095238095238095,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 40,\n",
       "       'gain': 0.023472222222222394}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.225,\n",
       "      'level': 5,\n",
       "      'split': [1, 49730.0],\n",
       "      'n_samples': 78,\n",
       "      'gain': 0.010898218590526254,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.26153846153846155,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 63,\n",
       "       'gain': 0.01840414104450161},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.11764705882352941,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 15,\n",
       "       'gain': 0.035555555555555465}}}}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.9316606140640475,\n",
       "   'level': 2,\n",
       "   'split': [1, 30532.545454545452],\n",
       "   'n_samples': 3027,\n",
       "   'gain': 0.007509453837285407,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.9872958257713249,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1651,\n",
       "    'gain': 0.00024133700317513843},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.8642960812772134,\n",
       "    'level': 3,\n",
       "    'split': [6, 1.0],\n",
       "    'n_samples': 1376,\n",
       "    'gain': 0.00816405585876312,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 0.9044715447154471,\n",
       "     'level': 4,\n",
       "     'split': [1, 44211.63636363637],\n",
       "     'n_samples': 982,\n",
       "     'gain': 0.0011786261141377707,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.9189944134078212,\n",
       "      'level': 5,\n",
       "      'split': [0, 2017.0],\n",
       "      'n_samples': 714,\n",
       "      'gain': 0.0015632224032787745,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.9090909090909091,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 636,\n",
       "       'gain': 0.0008129098073457186},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.9875,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 78,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.8629629629629629,\n",
       "      'level': 5,\n",
       "      'split': [0, 2016.0],\n",
       "      'n_samples': 268,\n",
       "      'gain': 0.0029666274073334997,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8113207547169812,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 104,\n",
       "       'gain': 0.01542136864088528},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.891566265060241,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 164,\n",
       "       'gain': 0.0004500731907840505}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.7626262626262627,\n",
       "     'level': 4,\n",
       "     'split': [1, 46088.36363636364],\n",
       "     'n_samples': 394,\n",
       "     'gain': 0.012432872082331625,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.7993827160493827,\n",
       "      'level': 5,\n",
       "      'split': [0, 2016.0],\n",
       "      'n_samples': 322,\n",
       "      'gain': 0.0017790429580819,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.7545454545454545,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 108,\n",
       "       'gain': 0.0071004617233656475},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.8194444444444444,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 214,\n",
       "       'gain': 0.001081668321998075}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.5945945945945946,\n",
       "      'level': 5,\n",
       "      'split': [1, 46625.454545454544],\n",
       "      'n_samples': 72,\n",
       "      'gain': 0.0061262040428707865,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.4444444444444444,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 7,\n",
       "       'gain': 0.27551020408163274},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6119402985074627,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 65,\n",
       "       'gain': 0.006028804287149692}}}}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12348573661586557,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 2557,\n",
       "  'gain': 0.047676779790769896,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03826530612244898,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 1958,\n",
       "   'gain': 0.0045681349880153654,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.00727802037845706,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1372,\n",
       "    'gain': 6.539810508043517e-05},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11224489795918367,\n",
       "    'level': 3,\n",
       "    'split': [1, 73046.45454545454],\n",
       "    'n_samples': 586,\n",
       "    'gain': 0.011500104783552484,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.21395348837209302,\n",
       "     'level': 4,\n",
       "     'split': [2, 0.7272727272727479],\n",
       "     'n_samples': 213,\n",
       "     'gain': 0.03131873045174638,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.17435897435897435,\n",
       "      'level': 5,\n",
       "      'split': [3, 1.0],\n",
       "      'n_samples': 193,\n",
       "      'gain': 0.0022441355404702046,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.2033898305084746,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 116,\n",
       "       'gain': 0.012082951847495582},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.13924050632911392,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 77,\n",
       "       'gain': 0.017844493169168696}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.5909090909090909,\n",
       "      'level': 5,\n",
       "      'split': [0, 2013.0],\n",
       "      'n_samples': 20,\n",
       "      'gain': 0.10666666666666669,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.47058823529411764,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 15,\n",
       "       'gain': 0.08752136752136752},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.8571428571428571,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 5,\n",
       "       'gain': 0}}},\n",
       "    'sr': {'y_pred': 0,\n",
       "     'y_prob': 0.056,\n",
       "     'level': 4,\n",
       "     'split': [1, 86796.45454545454],\n",
       "     'n_samples': 373,\n",
       "     'gain': 0.0027469921069710745,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.09883720930232558,\n",
       "      'level': 5,\n",
       "      'split': [3, 1.0],\n",
       "      'n_samples': 170,\n",
       "      'gain': 0.005168695203297352,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.14150943396226415,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 104,\n",
       "       'gain': 0.02688315957546719},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.04411764705882353,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 66,\n",
       "       'gain': 0.0022038567493111866}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.024390243902439025,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 203,\n",
       "      'gain': 0.0008738844612075081}}}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.40266222961730447,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 599,\n",
       "   'gain': 0.03360777305969753,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.30213903743315507,\n",
       "    'level': 3,\n",
       "    'split': [8, 1.0],\n",
       "    'n_samples': 372,\n",
       "    'gain': 0.02792228272448688,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.2598187311178248,\n",
       "     'level': 4,\n",
       "     'split': [1, 60734.36363636364],\n",
       "     'n_samples': 329,\n",
       "     'gain': 0.020406917448241912,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.39344262295081966,\n",
       "      'level': 5,\n",
       "      'split': [6, 1.0],\n",
       "      'n_samples': 120,\n",
       "      'gain': 0.024785915984516682,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.4380952380952381,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 103,\n",
       "       'gain': 0.009128769704447703},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.15789473684210525,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 17,\n",
       "       'gain': 0.03898500576701286}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.1848341232227488,\n",
       "      'level': 5,\n",
       "      'split': [6, 1.0],\n",
       "      'n_samples': 209,\n",
       "      'gain': 0.008907488615280956,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.2222222222222222,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 160,\n",
       "       'gain': 0.009933226671492434},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.0784313725490196,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 49,\n",
       "       'gain': 0.0029987505206162113}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.6222222222222222,\n",
       "     'level': 4,\n",
       "     'split': [1, 82538.7272727273],\n",
       "     'n_samples': 43,\n",
       "     'gain': 0.06528625511859693,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.7027027027027027,\n",
       "      'level': 5,\n",
       "      'split': [1, 60500.63636363636],\n",
       "      'n_samples': 35,\n",
       "      'gain': 0.027591836734693898,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8333333333333334,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 10,\n",
       "       'gain': 0.046666666666666606},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6296296296296297,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 25,\n",
       "       'gain': 0.05404675324675312}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.3,\n",
       "      'level': 5,\n",
       "      'split': [1, 85832.72727272728],\n",
       "      'n_samples': 8,\n",
       "      'gain': 0.04166666666666674,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.5,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 2,\n",
       "       'gain': 0.5},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.25,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 6,\n",
       "       'gain': 0.05555555555555547}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.5676855895196506,\n",
       "    'level': 3,\n",
       "    'split': [1, 81106.09090909094],\n",
       "    'n_samples': 227,\n",
       "    'gain': 0.02910175577937174,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 0.6057692307692307,\n",
       "     'level': 4,\n",
       "     'split': [1, 56288.72727272727],\n",
       "     'n_samples': 206,\n",
       "     'gain': 0.01833397012522614,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.7272727272727273,\n",
       "      'level': 5,\n",
       "      'split': [1, 52392.0],\n",
       "      'n_samples': 75,\n",
       "      'gain': 0.020388007054673807,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.5652173913043478,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 21,\n",
       "       'gain': 0.024187452758881345},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.7857142857142857,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 54,\n",
       "       'gain': 0.013640067246305065}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.5338345864661654,\n",
       "      'level': 5,\n",
       "      'split': [8, 1.0],\n",
       "      'n_samples': 131,\n",
       "      'gain': 0.04889445575665913,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.4519230769230769,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 102,\n",
       "       'gain': 0.03565124802149011},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.8064516129032258,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 29,\n",
       "       'gain': 0.01229897068184821}}},\n",
       "    'sr': {'y_pred': 0,\n",
       "     'y_prob': 0.21739130434782608,\n",
       "     'level': 4,\n",
       "     'split': [8, 1.0],\n",
       "     'n_samples': 21,\n",
       "     'gain': 0.07558578987150422,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.15,\n",
       "      'level': 5,\n",
       "      'split': [1, 84823.72727272728],\n",
       "      'n_samples': 18,\n",
       "      'gain': 0.06419753086419752,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.42857142857142855,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 5,\n",
       "       'gain': 0.21333333333333332},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.06666666666666667,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 13,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.6,\n",
       "      'level': 5,\n",
       "      'split': [1, 89720.90909090909],\n",
       "      'n_samples': 3,\n",
       "      'gain': 0.4444444444444444,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.5,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 1,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.75,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 2,\n",
       "       'gain': 0}}}}}}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=6, num_pct=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = tree_predict(X_test, tree, proba=False)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8830831408775982"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_manual = np.sum(prediction==y_test)/prediction.shape[0]\n",
    "\n",
    "accuracy_manual\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy obtenido es de 0.8831 con el arbol estimado manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de clasificación y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4390, 1069, 1974, ..., 6622, 3693, 4845]),\n",
       " array([3259, 5121, 6516, ..., 4790, 5933, 3270]),\n",
       " array([5101, 5526, 4995, ..., 1079, 1870, 5611]),\n",
       " array([1978,  796, 5720, ..., 5609, 2625, 1491]),\n",
       " array([6305, 6422,  203, ..., 3188, 1699, 6963]),\n",
       " array([1846, 3937, 5676, ..., 2573,  301, 1052]),\n",
       " array([ 588, 1684, 1192, ..., 2941, 4149, 1348]),\n",
       " array([ 802, 3388, 6581, ..., 1779, 4226, 2455]),\n",
       " array([5082, 3871, 6339, ..., 2163, 4847, 1097]),\n",
       " array([2406, 6488,  578, ..., 5785, 3036, 6680])]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 2\n",
    "\n",
    "#Se generan los índices de las muestras aleatorias\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257343</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242354</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266376</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396954</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127182</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187272</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254404</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9\n",
       "257343  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "326011  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "242354  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "266376  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "396954  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "317876  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "127182  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "187272  1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "372243  1.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "254404  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Se construye un arbol de decision con cada muestra de bootstrap y se almacenan las predicciones\n",
    "\n",
    "\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train_i = X_train.iloc[sample,:]\n",
    "    y_train_i = y_train.iloc[sample]\n",
    "    tree_bag = tree_grow(X_train_i, y_train_i, max_depth=6)\n",
    "    y_pred.iloc[:,i] = tree_predict(X_test, tree_bag)\n",
    "\n",
    "y_pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257343    0\n",
       "326011    0\n",
       "242354    1\n",
       "266376    1\n",
       "396954    1\n",
       "         ..\n",
       "144298    1\n",
       "364521    1\n",
       "120072    1\n",
       "99878     0\n",
       "387162    0\n",
       "Length: 3464, dtype: int32"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se calcula la prediccion para cada observacion mediante votacion mayoritaria\n",
    "\n",
    "prediccion_bag = (y_pred.sum(axis=1) >= (n_B / 2)).astype(np.int)\n",
    "\n",
    "prediccion_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859699769053118"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_bagging = np.sum(prediccion_bag==y_test)/prediction.shape[0]\n",
    "\n",
    "accuracy_bagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy obtenido es de 0.8859, ligeramente superior (aunque muy similar) al obtenido con un solo arbol (0.8831)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de clasificación y el parámetro `max_features` igual a `log(n_features)`. Presenten el acurracy del modelo en el set de test y comenten sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8646073903002309"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clfBagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, max_features= int(np.log2(X_train.shape[1])), bootstrap=True,\n",
    "                        random_state=420, n_jobs=-1, oob_score=True)\n",
    "\n",
    "\n",
    "clfBagging.fit(X_train, y_train)\n",
    "\n",
    "predicted_clfBag = clfBagging.predict(X_test)\n",
    "\n",
    "accuracy_bagging_lib = metrics.accuracy_score(y_test, predicted_clfBag)\n",
    "\n",
    "accuracy_bagging_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al estimar el arbol mediante bagging con el parametro max_features = log2(10), para cada muestra de bootstrap tambien se escogerian aleatoriamente 3 variables explicativas para construir el arbol. Esto genera mas variabilidad. El accuracy estimado es de 0.86 el cual es un poco inferior a los estimados anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para clasificación y presenten el acurracy del modelo en el set de test y comenten sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 4\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clfRF = RandomForestClassifier()\n",
    "\n",
    "clfRF.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFpredict = clfRF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455542725173211"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, RFpredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy obtenido con el modelo de Random Forest es 0.845, inferior a los estimados anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para clasificación. Presenten el acurracy del modelo en el set de test, comenten sus resultados y análicen cómo cada parámetro afecta el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la calibracion se analizara cada parametro individualmente y finalmente se realizara un gridsearch para hayar el optimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Calibracion max_depth\n",
    "\n",
    "max_depths = np.arange(1,30,1)\n",
    "\n",
    "accuracy_max_depth = []\n",
    "\n",
    "for md in max_depths:\n",
    "\n",
    "    clfRF_md = RandomForestClassifier(max_depth=md)\n",
    "    accuracy_max_depth.append(cross_val_score(clfRF_md, X_train, y_train).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEHCAYAAACwUAEWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtkklEQVR4nO3deXxU5dn/8c+VmewJYUkIkAABAoQdISKLoqIirrhURXGjdaHVqvXxqbRPH621i6219vkV61qttYobVKUugLuisu+QQMIaICRhywJJmMz1+2MmbUwhDCGTMzO53q9XXsycOTNzHeaV+ebc97nvW1QVY4wx5liinC7AGGNMaLOgMMYY0yQLCmOMMU2yoDDGGNMkCwpjjDFNcjtdQEtKTU3VrKwsp8swxpiwsWzZsjJVTWtqn4gKiqysLJYuXep0GcYYEzZEZNvx9rGmJ2OMMU2yoDDGGNMkCwpjjDFNsqAwxhjTJAsKY4wxTbKgMMYY0yQLCmOMMU2yoIhg2/ce4pO8Erxem0reGNN8ETXgzvzblrIqrnrqa8oqa+iTlsj3z8pm8vBuRLvsbwNjzImxb40ItPPAYa5/bhFeVR6ePIgYt4v73ljFWY9+yotfbaX6SJ3TJRpjwohE0gp3ubm52tan8CitqOHqp31nErNuHc3gjBRUlU/zS5n5SQHLtu0nNSmG757ei+tH96RdXLTTJRtjHCQiy1Q1t8l9LCgix4FDtUx55hu27T3ES98bRW5Wx289rqos3rKPJz4t5PONpSTHublpTBbTxmXRKSnWoaqNMU6yoGhDKms8XP/cItbvKucvN+dyRt8mJ4NkTdFBnvysgPfXFhPrjmLKqT24aWwWWZ0SEJFWqtoY4zQLijai+kgd015YwuKt+3hy6ggmDuoS8HMLSip56rNC3lqxE49XyWgfz+nZqYzN7sTYPqmkJduZhjGRzIKiDaj1eJn+92V8kl/C41cP57JTMpr1OrsOHOajvBIWbirjq8Iyyqs9AOR0SWZcdiqnZ6cyqldHEmPtQjljIokFRYSr8yp3vbqCd1fv5leXD2bqaT1b7HXX7jzIwsIyFhaUsWTrfmo9XtxRwik92jO2TypX5WaS2SGhRd7PGOMcC4oI5vUqM+as5vWlRfz0whxuG98naO9VfaSOZdv282VBGV8VlLF650E6Jcby6m2jye6cFLT3NcYEnwVFhFJVfvHP9bywcCt3Tcjm3on9W/X9N+2p4NpnFyECs261sDAmnAUSFEEdcCcik0QkX0QKRGTGUR5PEZG5IrJKRNaJyLQGj/3Iv22tiMwSkbhg1hpOHv9wEy8s3Mq0cVn86Lx+rf7+fdOTmXXraagq1z77DYWlla1egzGm9QQtKETEBTwBXAAMBK4VkYGNdrsDWK+qw4CzgMdEJEZEMoC7gFxVHQy4gCnBqjWczFlexP/7aBNX52byvxcNdOxSVl9YjPaFxTMWFsZEsmCeUYwCClR1s6rWAq8Ckxvto0Cy+L7tkoB9gMf/mBuIFxE3kADsCmKtYeFInZc/LNjIsMwUfnPFUKKinB3v0Dc9mVduHU2d1xcWmy0sjIlIwQyKDGBHg/tF/m0NzQQG4AuBNcDdqupV1Z3A74HtwG7goKrOP9qbiMhtIrJURJaWlpa29DGElLdX7qJo/2HuOqcvLodDol6/9GRm3eYPi2e/YUtZldMlGWNaWDCD4mjfZI17zs8HVgLdgOHATBFpJyId8J199PI/ligi1x/tTVT1GVXNVdXctLSmRyOHszqv8udPChjYtR0Tcjo7Xc639POfWXjqlCnPfG1hYUyECWZQFAHdG9zP5D+bj6YBc9SnANgC5ADnAltUtVRVjwBzgLFBrDXkvbtmN5vLqvjhhOyQnGKjfxdfWByp8zVDbbWwMCZiBDMolgB9RaSXiMTg64x+p9E+24FzAEQkHegPbPZvHy0iCf7+i3OADUGsNaR5vcoTHxeQ3TmJ809geo7W5guL06it8zLFwsKYiBG0oFBVD3AnMA/fl/zrqrpORKaLyHT/bg8DY0VkDfARcL+qlqnqIuBNYDm+voso4Jlg1RrqFmzYQ/6eCu48O9vxDuzjyenSjpdvOY0aTx3XPvsN2/ZaWBgT7mzAXYhTVS6duZDy6iN8dO+ZuMNkhbr1u8qZ+tw3xEe7eO32MXTvaNN9GBOKHB9wZ07eZxtLWbPzID84q0/YhATAwG7tePmW0VTWeLj39ZW2brcxYSx8vnnaIFXlTx8XkNE+nstPyXS6nBM2sFs7fnbxQJZs3c9rS3cc/wnGmJBkQRHCvt68l2Xb9jP9zN7EuMPzo7pqZCaje3fk1+9toKSi2ulyjDHNEJ7fPm3EzI8LSEuO5arc7sffOUSJCL++fAg1Hi+/mLve6XKMMc1gQRGilm3bx1eFe7l9fG/iol1Ol3NSeqclcefZ2fxz9W4+yStxuhxjzAmyoAhRMz8uoENCNNed1sPpUlrE9DP70LdzEj97ay1VNZ7jP8EYEzIsKELQ2p0H+SS/lFvO6E1CTGQsPRrjjuLXVwxh54HDPL5go9PlGGNOgAVFCJr5cQHt4tzcMKZlljYNFadmdeTaUT14fuEW1u486HQ5xpgAWVCEmPziCj5YV8zN43rRLi7a6XJa3IwLcuiUFMtP5qzBU+d1uhxjTAAsKELME58UkBjjYtrYLKdLCYqU+GgevGQga3Ye5K9fbXW6HGNMACwoQsjm0kr+uXoX14/pSYfEGKfLCZqLhnTl7P5p/GHBRor2H3K6HGPMcVhQhJAnPy0k2hXFLaf3drqUoBIRHr5sMKrwwNvriKT5xoyJRBYUIWLHvkP8Y8VOrh3Vg7TkWKfLCbrMDgn818R+fJxXwntrip0uxxjTBAuKEPH054VEiXD7mZF9NtHQzWOzGJzRjp/PXcfBw0ecLscYcwwWFCGg+GA1ry8p4ju5mXRNiXe6nFbjdkXxm8uHsreyht9+kOd0OcaYY7CgcJjXq8yYsxoEvn9mH6fLaXVDMlOYNq4XryzazpKt+5wuxxhzFBYUDnt+4RY+zS/lZxcNaLOL+9x7Xj8y2sfz0zlrqPXY2ApjQo0FhYPW7jzIbz/I47yB6dwwOrJGYZ+IxFg3D182iE0llTz8z/V2FZQxIcaCwiGVNR5+OGsFnRJj+d2VQxEJ7bWwg21CTjq3je/NS99s4/mFW50uxxjTQGTMOBeGHnx7Hdv2VvHKraMjenDdiZgxKYcd+w7xy3fX071DPBMHdXG6JGMMdkbhiLdW7GT28iLunNCX0b07OV1OyIiKEv5w9XCGZrbn7ldXsrrogNMlGWOwoGh12/ZW8bO31pLbswN3Tch2upyQEx/j4rkbc+mYGMP3XlzKzgOHnS7JmDbPgqIV1Xq83DVrBVECf5wyHLfL/vuPJi05lr9OO5XqI3V894UllFfbYDxjnGTfVK3osQX5rCo6yG+vHEpmh7Z5KWyg+qYn8+TUkRSWVnLHy8s5YlOSG+MYC4pW8vnGUp7+bDPXndaDC4Z0dbqcsHB631R+dflgvthUxgNvr7XLZo1xiF311ApKK2q49/VV9O2cxP9eNNDpcsLKNaf2YNveQ/z500KyOiVyexscvW6M0ywogszrVe57YxUV1Uf4+y2jiI9xOV1S2LlvYn+27TvEb97Po3vHBC60MzJjWpU1PQXZX77cwmcbS/nZxQPJ6dLO6XLCUlSU8NhVwxjRoz0/em0lK7bvd7okY9oUC4ogWl10gN/Ny2PiwHSuP62H0+WEtbhoF8/emEt6uzhu/dtSduyzlfGMaS0WFEFyqNbDXbNWkJoUy+++Y1N0tIROSbG8MO1UjtQp0/66hMoaj9MlGdMmWFAEyezlO9m69xC/v2oY7RNsio6W0ictiSenjqCgpJKXvt7mdDnGtAkWFEGgqryyaDsDurZjbB+boqOljc1O5Yy+qTy/cAs1njqnyzEm4gU1KERkkojki0iBiMw4yuMpIjJXRFaJyDoRmebf3l9EVjb4KReRe4JZa0taueMAG3aXc91pPazJKUhuH9+H0ooa3lqx0+lSjIl4QQsKEXEBTwAXAAOBa0Wk8SCCO4D1qjoMOAt4TERiVDVfVYer6nBgJHAI+Eewam1pryzaTkKMi8uGd3O6lIg1LrsTg7q14+nPN+P12kA8Y4IpmGcUo4ACVd2sqrXAq8DkRvsokCy+P7uTgH1A4x7Kc4BCVQ2LBumDh48wd/UuLh3WjeS4aKfLiVgiwu1n9mFzaRULNuxxuhxjIlowgyID2NHgfpF/W0MzgQHALmANcLeqNp7UZwow61hvIiK3ichSEVlaWlp68lWfpLdW7KT6iJfr7HLYoLtwcBe6d4znqc8KbXoPY4IomEFxtMb5xr/N5wMrgW7AcGCmiPxrVJqIxACXAm8c601U9RlVzVXV3LS0tJOt+aTUd2IPzmjH0Mz2jtbSFrhdUdx6Rm9WbD/A0m02CM+YYAlmUBQB3Rvcz8R35tDQNGCO+hQAW4CcBo9fACxX1bBoW1i+fT/5eyqYelrbXf+6tV01sjsdEqJ5+rNCp0sxJmIFMyiWAH1FpJf/zGAK8E6jfbbj64NARNKB/sDmBo9fSxPNTqHm5UXbSYp1c+kw68RuLfExLm4am8WHG0rYtKfC6XKMiUhBCwpV9QB3AvOADcDrqrpORKaLyHT/bg8DY0VkDfARcL+qlgGISAJwHjAnWDW2pIOHjvDu6t1MHt6NxFiba7E13Tgmi7joKJ75fPPxdzbGnLCgfqOp6nvAe422PdXg9i5g4jGeewgIm9Fqs5cXUeOxTmwndEyM4Zrc7ryyeDv/NbE/XVLinC7JmIhiI7NbgKryyuLtDOvenkHdUpwup0265YzeeBVeWLjF6VKMiTgWFC1gydb9FJRUMnWUnU04pXvHBC4a0pWXF23n4GFbY9uYlmRB0QJeWbSN5Fg3Fw+zBXWcdNv43lTWeHhl0XanSzEmolhQnKT9VbW8t7aYy0dkkBBjndhOGpyRYpMFGhMEFhQnafbyImqtEztk2GSBxrQ8C4qTUN+JPaJHe1vmNETYZIHGtDwLipPwzeZ9bC6t4jobiR0yGk4W+KFNFmhMi7CgOAmvLN5Ouzg3Fw+1TuxQUj9Z4NM2AM+YFmFB0Ux7K2v4YO1urhiRSVy0y+lyTAP1kwUu27afpVv3OV2OMWHPgqKZZi8v4kidMtU6sUNS/WSBT31mZxXGnCwLimZQVWYt3sGpWR3om57sdDnmKP49WeAeCkpsskBjToYFRTN8XbiXLWVVdklsiKufLPBpO6sw5qRYUDTDy4u30z4hmgsGWyd2KKufLPCtlTsp2n/I6XKMCVsWFCeorLKG+euKudI6scPC7Wf2QUR4fMEmp0sxJmxZUJygN5b6OrGvtQkAw0K39vFMG5vFnBVF5BWXO12OMWHJguIEeL3KrMXbOa1XR7I7JzldjgnQ98/qQ3Ksm9++n+d0KcaEJQuKE7C5rIrt+w5xxYgMp0sxJ6B9Qgx3nJ3NJ/mlfF241+lyjAk7FhQnoL7pYnCGLU4Ubm4am0XXlDge+SAPVZsDypgTYUFxAvKLK3BFiTU7haG4aBc/Oq8fq3Yc4P21xU6XY0xYOW5QiMjFImKBAmzYXUHv1ERi3Xa1Uzi6ckQm/dKTeHRePkfqvE6XY0zYCCQApgCbROR3IjIg2AWFsrzicnK62nTi4coVJdw/KYctZVW8tmSH0+UYEzaOGxSqej1wClAIvCAiX4vIbSLSpuauqKg+QtH+w+R0aVOHHXEm5HRmVFZH/vjhJqpqPE6XY0xYCKhJSVXLgdnAq0BX4HJguYj8MIi1hZSNe3zzBVlQhDcRYcaFOZRV1vCXL7c4XY4xYSGQPopLROQfwMdANDBKVS8AhgH3Bbm+kLFhtz8orOkp7I3o0YFJg7rw9GeFlFXWOF2OMSEvkDOKq4DHVXWoqj6qqiUAqnoI+G5Qqwsh+cUVJMe56ZYS53QppgX896T+VHu8zPy4wOlSjAl5gQTFg8Di+jsiEi8iWQCq+lGQ6go5ecXl5HRJRkScLsW0gD5pSVxzandeXrSNbXurnC7HmJAWSFC8ATS8lrDOv63NUFXyiivI6WLNTpHknnP64o6K4vfzNzpdijEhLZCgcKtqbf0d/+2Y4JUUenYdrKai2kN/68iOKJ3bxXHLGb2Yu2oXa4oOOl2OMSErkKAoFZFL6++IyGSgLHglhZ683b6pOwZ0taCINLeN702HhGh++4FNGGjMsQQSFNOBn4rIdhHZAdwP3B7cskJLXrHviqd+tuxpxEmOi+aHE/ryZUEZn28sdbocY0JSIAPuClV1NDAQGKiqY1W1TV0qkldcQWaHeJLjop0uxQTB1NE96N4xnkfez8PrtQkDjWksoAF3InIR8APgRyLygIg8EODzJolIvogUiMiMozyeIiJzRWSViKwTkWkNHmsvIm+KSJ6IbBCRMYEeVEvL211uHdkRLNbt4r6J/Vm/u5y5q3c5XY4xISeQAXdPAdcAPwQE37iKngE8zwU8AVyA72zkWhEZ2Gi3O4D1qjoMOAt4TETqO8r/D/hAVXPwDe7bEMgBtbTqI3VsLquy/okId8nQbgzq1o7fz8/HYxMGGvMtgZxRjFXVG4H9qvoQMAboHsDzRgEFqrrZf6XUq8DkRvsokCy+wQlJwD7AIyLtgPHAX8B3pZWqHgjkgFpaQUkldV61M4oIFxUl3HVOX3bsO8yHG0qcLseYkBJIUFT7/z0kIt2AI0CvAJ6XATScorPIv62hmcAAYBewBrhbVb1Ab6AU3ySEK0TkORFJPNqb+CcoXCoiS0tLW74zMt/fkW2Xxka+cwekk9E+nr99vdXpUowJKYEExVwRaQ88CiwHtgKzAnje0YYwN+4pPB9YCXQDhgMz/WcTbmAE8KSqngJUAf/RxwGgqs+oaq6q5qalpQVQ1onJKy4n1h1FVqeEFn9tE1pcUcLU0T34qnAvBSUVTpdjTMhoMij8CxZ9pKoHVHU2vr6JHFUNpDO7iG83UWXiO3NoaBowR30KgC1Ajv+5Raq6yL/fm/iCo9XlFVfQLz0Zt8vWbmoLrsntTow7ir99vc3pUowJGU1++/mbgR5rcL9GVQMdwroE6Csivfwd1FOAdxrtsx04B0BE0oH+wGZVLQZ2iEh//37nAOsDfN8WlVdcYc1ObUinpFguHtqV2cuKqKg+4nQ5xoSEQP5Mni8iV8oJzoanqh7gTmAeviuWXlfVdSIyXUSm+3d7GBgrImuAj4D7VbV+1PcPgZdFZDW+Zqlfn8j7t4SyyhpKK2psDYo25qYxWVTV1vGPFTudLsWYkOAOYJ97gUR8VyNV4+t7UFU97mVAqvoe8F6jbU81uL0LmHiM564EcgOoL2jqO7IH2BoUbcqw7u0ZlpnCi19t5YbRPW3GYNPmBTIyO1lVo1Q1RlXb+e+3iW/OPLviqc26cUwWhaVVfFW41+lSjHFcIAPuxh/tpzWKc1re7nJSk2JJTYp1uhTTyi4a2pWOiTF2qawxBNb09N8NbsfhG0i3DJgQlIpCSF5xhY3IbqPiol1cc2p3nv6skJ0HDpPRPt7pkoxxTCBNT5c0+DkPGAzsCX5pzqrzKhv3VNDfZoxts6ae1gOAl7+xS2VN29acwQFF+MIiom3dW0WNx0uOdWS3WZkdEjh3QDqvLtlB9ZE6p8sxxjHHbXoSkT/x7xHVUfguVV0VxJpCQt5uX0e2XRrbtt04Jov56/fw3prdXDEi0+lyjHFEIH0USxvc9gCzVHVhkOoJGfnF5biihOzOSU6XYhw0LrsTvdMS+dvX2ywoTJsVSFC8CVSrah34pg8XkQRVPRTc0py1obiCXqmJxEW7nC7FOEhEuHF0T34+dz2rdhxgWPf2TpdkTKsLpI/iI6DhJR/xwIfBKSd05BWXW7OTAeDKkZkkxrhs/ifTZgUSFHGqWll/x387oqdSrazxsGPfYQsKA/jW1b5iRCZzV+9iX1Wt0+UY0+oCCYoqEfnXzK0iMhI4HLySnFc/dYctVmTq3TCmJ7UeL68t2XH8nY2JMIEExT3AGyLyhYh8AbyGb7K/iJVXXA5Ajg22M3790pMZ07sTf/9mG3XexsuqGBPZAhlwtwTfGhHfB34ADFDVZcEuzEl5uytIjnXbaFzzLTeO6cnOA4f5OM+WSjVtSyBzPd0BJKrqWlVdAySJyA+CX5pz8v1rUNisoaah8wam0zUlzuZ/Mm1OIE1Pt6rqgfo7qrofuDVoFTlMVdlQXG7NTuY/uF1RTD2tB19sKqOwtPL4TzAmQgQSFFENFy0SERcQE7ySnLXrYDUV1R76W0e2OYprTu1BtEt4yS6VNW1IIEExD3hdRM4RkQnALOD94JblnHx/R/YAuzTWHEVaciwXDfEtlVpV43G6HGNaRSBBcT++QXffB+4AVvPtAXgRZYN/jqd+FhTmGG4Yk0VFjceWSjVtRiBXPXmBb4DN+JYmPQffGtgRKa+4goz28bSLi3a6FBOiRvRoz+CMdjz3xWYO19qssibyHTMoRKSfiDwgIhuAmcAOAFU9W1VntlaBrS2/uNwWKzJNEhFmTBrA1r2HeOT9iP2byZh/aeqMIg/f2cMlqnq6qv4JiOg/n2o8dRSWVtmIbHNcp/dNZdq4LF78ehufbSx1uhxjgqqpoLgSKAY+EZFnReQcIKIHFhSUVFLnVbs01gTk/kk59EtP4r43VtkcUCaiHTMoVPUfqnoNvlHZnwI/AtJF5EkRmdhK9bUqW6zInIi4aBd/vOYUDhyq5adz1qBqU3uYyBRIZ3aVqr6sqhcDmcBKYEawC3NC/p4KYtxRZHVKdLoUEyYGdmvHf03szwfrinlzWZHT5RgTFCe0Zraq7lPVp1V1QrAKctKG3eX0S0/C7WrOUuKmrbr1jN6c1qsjP39nHdv3RvR6XqaNsm/EBvKKK+ifbh3Z5sS4ooTHrh5GlAj3vr7SZpc1EceCwm9vZQ2lFTV2aaxplswOCfziskEs3bafpz4rdLocY1qUBYWfLVZkTtZlwzO4eGhXHl+wkdVFB5wux5gWY0Hht8EfFP3tiifTTCLCry4bQmpSLPe8ttJGbZuIYUHhl19cTmpSDGnJsU6XYsJYSkI0j109jM2lVfzGRm2bCGFB4ZdXXGHNTqZFjMtO5Xun9+JvX2/jk3xbDc+Ev6AGhYhMEpF8ESkQkf8YeyEiKSIyV0RWicg6EZnW4LGtIrJGRFaKyNJg1lnn1X+tamdMS/jv8/vTPz2ZH7+52kZtm7AXtKDwL3D0BHABMBC4VkQGNtrtDmC9qg4DzgIeE5GGiyKdrarDVTU3WHUCbNtbRY3HayOyTYuJi3bx+DXDOXjoCDNmr7ZR2yasBfOMYhRQoKqbVbUWeBWY3GgfBZL9K+glAfuAVl8NJs/fkT2gqzU9mZYzsFs77ju/H/PX7+GNpTZq24SvYAZFBv6pyf2K/NsamgkMAHYBa4C7/etfgC9E5ovIMhG5LYh1kre7nCiB7M5JwXwb0wbdcrpv1PbD766npLza6XKMaZZgBsXRZpptfP59Pr65o7oBw4GZIlL/Z/04VR2Br+nqDhEZf9Q3EblNRJaKyNLS0uZN95xXXEGv1ETiol3Ner4xxxIVJTxy5VBqPF4emrve6XKMaZZgBkUR0L3B/Ux8Zw4NTQPmqE8BsAXfbLWo6i7/vyXAP/A1Zf0HVX1GVXNVNTctLa1ZheYVV5BjzU4mSHqlJnLXhGzeXbObjzbscbocY05YMINiCdBXRHr5O6inAO802mc7vsWREJF0oD+wWUQSRSTZvz0RmAisDUaRR+q8JMa6GZKREoyXNwaA28b3oV96Eg+8vY6qmlbvhjPmpAQtKFTVA9wJzMO3xvbrqrpORKaLyHT/bg8DY0VkDfARcL+qlgHpwJcisgpYDLyrqh8Eo85oVxTv330G08/sE4yXNwaAGHcUv7liCDsPHOYPCzY6XY4xJ8QdzBdX1feA9xpte6rB7V34zhYaP28zMCyYtRnT2kb27MjU03rwwsItXDY8gyGZdhZrwoONzDamFf14Ug6pSbHMmLMaT533+E8wJgRYUBjTilLio/n5pYNYt6ucFxZudbocYwJiQWFMK7tgcBfOHdCZPyzYyI59tiKeCX0WFMa0MhHhocmDEYH/fXutTe9hQp4FhTEOyGgfz39N7M+n+aX8c/Vup8sxpkkWFMY45OaxWQzNTOGhues5eOiI0+UYc0wWFMY4xBUl/PryIew/VMsjH9giRyZ0WVAY46DBGSl87/RezFq8g8Vb9jldjjFHZUFhjMPuObcvGe3j+cmc1dR4bJ1tE3osKIxxWEKMm19ePpjC0iqe+nSz0+UY8x8sKIwJAWf378wlw7rxxCcFFJZWOl2OMd9iQWFMiHjg4oHEx7i4/aVlts62CSkWFMaEiLTkWJ66fiQ79h3ixucXUV5tl8ya0GBBYUwIGdOnE09dP5K83RV894UlHKq1tSuM8ywojAkxZ+d05v+mnMLy7fu5/aVldiWUcZwFhTEh6KKhXXnkyqF8samMu2atsCnJjaMsKIwJUVfndufBSwYyb90efvzmarxemzzQOCOoK9wZY07OtHG9qKrx8Pv5G0mMdfOLyYMQEafLMm2MBYUxIe6Os7OpqPHw9GebSYpzc/+kHKdLMm2MBYUxIU5EmDEph8pqD09+WkhSrJs7zs52uizThlhQGBMGRISHJw/mUG0dj87LJynWzU1js5wuy7QRFhTGhImoKOHR7wylqsbDg++sIzHWzXdGZjpdlmkD7KonY8KI2xXFn647hTP6pvLjN1fxzqpdTpdk2gALCmPCTKzbxdM3jCQ3qyN3v7qC15fscLokE+EsKIwJQwkxbl6cNooz+qbx49mreWHhFqdLMhHMgsKYMBUf4+LZG0dy/qB0Hpq7nic+KXC6JBOhLCiMCWOxbhdPXDeCy0/J4NF5+fz2gzxUbQS3aVl21ZMxYc7tiuKxq4YRH+PiyU8LOVTj4cFLBhEVZSO4TcuwoDAmAkRFCb+6bDCJMS6e/WILVbV1/PbKobgsLEwLsKAwJkKICD+9cACJsW7++OEmDh+p4/GrhxPjthZmc3IsKIyJICLCPef2IzHGza/e20B1bR1PTB1BXLTL6dJMGLM/NYyJQLeO780vLxvMx/klfPevS6iqsZXyTPMFNShEZJKI5ItIgYjMOMrjKSIyV0RWicg6EZnW6HGXiKwQkX8Gs05jItH1o3vy2FXD+GbzXm74yyLWFB20K6JMswSt6UlEXMATwHlAEbBERN5R1fUNdrsDWK+ql4hIGpAvIi+raq3/8buBDUC7YNVpTCS7YkQmCTEu7np1JZfM/JKM9vGcNzCdSYO7cGpWR+vsNgEJZh/FKKBAVTcDiMirwGSgYVAokCy+lViSgH2Ax79/JnAR8Cvg3iDWaUxEmzS4K9/8pBMfbtjD/HXFvLJ4O3/9aisdE2M4d0Bnzh/UhXHZqdaPYY4pmEGRATSchKYIOK3RPjOBd4BdQDJwjarWLw78R+DH/u3HJCK3AbcB9OjR46SLNiYSdUyM4erc7lyd252qGg+fbSxl3rpi3l9TzOtLi0iMcXFWji80zu6fRnJctNMlmxASzKA42jlt4wbS84GVwASgD7BARL4AxgMlqrpMRM5q6k1U9RngGYDc3FxrgDXmOBJj3Vw4pCsXDulKrcfLV4VlzFu3hwXr9/Du6t3ER7v4y825jO2T6nSpJkQEszO7COje4H4mvjOHhqYBc9SnANgC5ADjgEtFZCvwKjBBRP4exFqNaZNi3FGc1b8zv7liCIt+eg5vTh9DZod4pr+0jIKSSqfLMyEimEGxBOgrIr1EJAaYgq+ZqaHtwDkAIpIO9Ac2q+pPVDVTVbP8z/tYVa8PYq3GtHmuKCE3qyPP33wqMW4X0/66mL2VNU6XZUJA0IJCVT3AncA8fFcuva6q60RkuohM9+/2MDBWRNYAHwH3q2pZsGoyxhxf944JPHdTLqUVNdz6t6VUH6lzuiTjMImk66pzc3N16dKlTpdhTET4YG0x3395GRcO6cqfppxikwxGKBFZpqq5Te1jI7ONMUc1aXAXfnrBAN5dvZtH5+c7XY5xkM31ZIw5plvO6MXWvVU8+WkhPTsmMGWUXYLeFllQGGOOSUR46NJBFO0/zP+8tZaMDvGc0TfN6bJMK7OmJ2NMk9yuKGZedwp9Oyfxg78vZ+OeCqdLMq3MgsIYc1zJcdE8f/OpxMe4mPbCEkoqqp0uybQiCwpjTEC6tY/n+ZtPZV9VLbe+uJTDtXbZbFthfRTGmIANzkjhT9eewq0vLeWe11bw5NSRR71sttbjZU95NXvKqykur6b4YDVVNXUkxrpIinWTGOsmKc5NUuy3fxJj3bYiXwiyoDDGnJBzB6bzwMUDeWjueu57cxVZnRL/FQbFB33hsLeq9vgvdAwx7igGd2vH/1w0kJE9O7Rg5aa5LCiMMSds2rhe7Nh3mOcXbgGgU2IM6e3i6JISx7Du7enSLo4uKbH/2talXRxJsW6qauuorPFQVeOhssZDZbXvdkX9tmrf7bdX7uTKJ7/i8lMymHFBDunt4hw+4rbNRmYbY5qtrLKG5Dg3se6WXcuiqsbDnz8t4NkvtuCOEu44O5vvnd7rpNbMqPV4cUVJqy7WVH2kjs2lVRSUVlJYUsm+qlom5HTmjL6puF2h0cQWyMhsCwpjTMjavvcQv3x3PfPX76FHxwT+56IBTByYjm+ts+M7cKiWDzeUMG9dMZ9vLMXjVdKSYklPiaNLu1j/mU/8v89+/GdACTEn1tiyv6qWwtJKCkp8P4WllRSUVlK0/zD1X7FRAnHRLg7V1pGWHMtlw7tx5chMcro4u4CnBYUxJiJ8uamMX/xzHRv3VHJ6dioPXDKQfulHX9Os+GA189cX88HaYhZt2UedV+maEsfEgekkx0VTXN/JftDX0V5R7fmP10iOdRMbHdhf/LUeL+UNXiPWHUXvtCSyOyeRnZZEn86JZHdOIqtTIlEifJxXwuzlRXySV4LHqwzs2o4rR2YyeXg3UpNim/cfdBIsKIwxEcNT5+Xv32zjDws2UlVbxw2je/Kjc/uRkhBNYWkl89YVM2/dHlbtOABAn7REzh/UhUmDuzAkI+WYZyFVNR5fePiDo7i8mpLyGo7UeY+6f2OuKKFHxwT6+IMho318QBMo7quq5Z2VO5m9fCdrdh7EHSWc1T+NK0dkMmFA5xZvzjsWCwpjTMTZV1XLY/PzmbV4Oynx0aQmxbLJv8jS0MwUzh/UhfMHdSG7c5LDlQZu454KZi8v4q0VO9lTXkNKfDQXDunKmf1SGdM7lZSE4C1Na0FhjIlY63eV8+i8PGo8XiYOTGfioC50ax/vdFknpc6rLCwoY/byIhas38Oh2jqixDd+ZVx2KqdnpzKyZ4eT6tRvzILCGGPCVK3Hy6qiAywsKGNhQRkrth/A41Vi3FGcmtWBcdmpjOuTyuCMlJO6ksuCwhhjIkRljYclW/bxpT848op9kzO2i3MzLjuVmdeNaFZgBBIUNuDOGGPCQFKsm7NzOnN2TmcASitq+KqwjK8K9rK3qjao40MsKIwxJgylJccyeXgGk4dnBP29QmNooDHGmJBlQWGMMaZJFhTGGGOaZEFhjDGmSRYUxhhjmmRBYYwxpkkWFMYYY5pkQWGMMaZJETWFh4iUAtsabEoFyhwqJ5gi9bggco/Njiv8ROqxNT6unqqa1tQTIiooGhORpcebwyQcRepxQeQemx1X+InUY2vOcVnTkzHGmCZZUBhjjGlSpAfFM04XECSRelwQucdmxxV+IvXYTvi4IrqPwhhjzMmL9DMKY4wxJ8mCwhhjTJMiMihEZJKI5ItIgYjMcLqeliQiW0VkjYisFJGwXfdVRJ4XkRIRWdtgW0cRWSAim/z/dnCyxuY6xrH9XER2+j+3lSJyoZM1NoeIdBeRT0Rkg4isE5G7/dvD+nNr4rjC+jMTkTgRWSwiq/zH9ZB/+wl/XhHXRyEiLmAjcB5QBCwBrlXV9Y4W1kJEZCuQq6phPRBIRMYDlcDfVHWwf9vvgH2q+og/4Duo6v1O1tkcxzi2nwOVqvp7J2s7GSLSFeiqqstFJBlYBlwG3EwYf25NHNfVhPFnJiICJKpqpYhEA18CdwNXcIKfVySeUYwCClR1s6rWAq8Ckx2uyTSiqp8D+xptngy86L/9Ir5f1rBzjGMLe6q6W1WX+29XABuADML8c2viuMKa+lT670b7f5RmfF6RGBQZwI4G94uIgA+9AQXmi8gyEbnN6WJaWLqq7gbfLy/Q2eF6WtqdIrLa3zQVVs0zjYlIFnAKsIgI+twaHReE+WcmIi4RWQmUAAtUtVmfVyQGhRxlWyS1r41T1RHABcAd/mYOE/qeBPoAw4HdwGOOVnMSRCQJmA3co6rlTtfTUo5yXGH/malqnaoOBzKBUSIyuDmvE4lBUQR0b3A/E9jlUC0tTlV3+f8tAf6Br6ktUuzxtxfXtxuXOFxPi1HVPf5fWi/wLGH6ufnbumcDL6vqHP/msP/cjnZckfKZAajqAeBTYBLN+LwiMSiWAH1FpJeIxABTgHccrqlFiEiiv7MNEUkEJgJrm35WWHkHuMl/+ybgbQdraVH1v5h+lxOGn5u/c/QvwAZV/UODh8L6czvWcYX7ZyYiaSLS3n87HjgXyKMZn1fEXfUE4L+M7Y+AC3heVX/lbEUtQ0R64zuLAHADr4TrsYnILOAsfFMe7wEeBN4CXgd6ANuBq1Q17DqFj3FsZ+FrwlBgK3B7fTtxuBCR04EvgDWA17/5p/ja88P2c2viuK4ljD8zERmKr7Pahe+k4HVV/YWIdOIEP6+IDApjjDEtJxKbnowxxrQgCwpjjDFNsqAwxhjTJAsKY4wxTbKgMMYY0yQLCmOMMU2yoDCmlfmnik9t5nNvFpFuLfFaxgTKgsKY8HIz0O14OxnTkiwoTJslIlkikiciz4nIWhF5WUTOFZGF/kVdRvl/vhKRFf5/+/ufe6+IPO+/PcT//IRjvE8nEZnvf42naTBxpYhc719cZqWIPO1fTwURqRSRx0RkuYh85J+O4TtALvCyf/94/8v80L/fGhHJCeb/mWmbLChMW5cN/B8wFMgBrgNOB+7DN41DHjBeVU8BHgB+7X/eH4FsEbkceAHf9A6HjvEeDwJf+l/jHXxTJyAiA4Br8M0IPByoA6b6n5MILPfPFPwZ8KCqvgksBaaq6nBVPezft8y/35P+uo1pUW6nCzDGYVtUdQ2AiKwDPlJVFZE1QBaQArwoIn3xzfkTDaCqXhG5GVgNPK2qC5t4j/H4VhVDVd8Vkf3+7ecAI4ElvnnpiOffM3l6gdf8t/8OzOHY6h9bVv8+xrQkCwrT1tU0uO1tcN+L7/fjYeATVb3cv6jNpw3274tvydNA+gyONqmaAC+q6k+a+fx69TXXYb/TJgis6cmYpqUAO/23b67fKCIp+JqsxgOd/P0Hx/I5/iYlEbkAqF8p7SPgOyLS2f9YRxHp6X8sCqh/zevwrXcMUAEkn8TxGHPCLCiMadrvgN+IyEJ80zXXexz4s6puBL4HPFL/hX8UDwHjRWQ5vjVEtgOo6nrgZ/iWtl0NLADq10CoAgaJyDJgAvAL//a/Ak816sw2JqhsmnFjQpCIVKpqktN1GAN2RmGMMeY47IzCmBYiItOAuxttXqiqdzhRjzEtxYLCGGNMk6zpyRhjTJMsKIwxxjTJgsIYY0yTLCiMMcY06f8DlNL5gjvx1DcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(max_depths, accuracy_max_depth)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentra que el accuracy aumenta en la medida que aumenta el max_depth a valores 6-7 y posteriormente empiza a disminuir (ya que probablemente se genera overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_r = np.arange(1,X_train.shape[1],1)\n",
    "\n",
    "accuracy_max_features = []\n",
    "\n",
    "for mf in max_features_r:\n",
    "\n",
    "    clfRF_mf = RandomForestClassifier(max_features=mf)\n",
    "    accuracy_max_features.append(cross_val_score(clfRF_mf, X_train, y_train).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(max_features_r, accuracy_max_features)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de los max_features se genera un mejor resultado cuando se consideran todas las variables explicativas en cada particion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_r = np.arange(1,300,10)\n",
    "\n",
    "accuracy_n_estimators = []\n",
    "roc_auc = []\n",
    "\n",
    "for n_est in n_estimators_r:\n",
    "\n",
    "    clfRF_ne = RandomForestClassifier(n_estimators=n_est)\n",
    "    accuracy_n_estimators.append(cross_val_score(clfRF_ne, X_train, y_train).mean())\n",
    "    clfRF_ne.fit(X_train,y_train)\n",
    "    prediccionRFprob = clfRF_ne.predict_proba(X_test)[:,1]\n",
    "    roc_auc.append(metrics.roc_auc_score(y_test, prediccionRFprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(n_estimators_r, accuracy_n_estimators)\n",
    "plt.plot(n_estimators_r, roc_auc)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El numero de estimadores calculados en el Random Forest es mayor cuando es un poco menor a 20. A partir de 20el accuracy tiene a ser mas estable, aunque con una ligera tendencia negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                         'max_features': array([1, 2, 3, 4, 5, 6, 7, 8]),\n",
       "                         'n_estimators': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NO CORRER - Se demora mucho - gridsearch con todos los parametros\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clfRF=RandomForestClassifier()\n",
    "parameters = {'max_depth':max_depths , 'max_features': max_features_r, 'n_estimators': n_estimators_r}\n",
    "\n",
    "\n",
    "RF_calib = GridSearchCV(clfRF,parameters, n_jobs=-1)\n",
    "RF_calib.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'max_features': 2, 'n_estimators': 96}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_calib.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859699769053118"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se estima el modelo con los parametros optimos hallados con el gridsearch.\n",
    "\n",
    "clfRF_calib= RandomForestClassifier(max_depth=7, max_features=2, n_estimators=96)\n",
    "clfRF_calib.fit(X_train,y_train)\n",
    "predict_RF=clfRF_calib.predict(X_test)\n",
    "\n",
    "accuracy_RF_calib = metrics.accuracy_score(y_test, predict_RF)\n",
    "accuracy_RF_calib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene que el mejor modelo se obtiene con los siguientes parametros 'max_depth': 7, 'max_features': 2, 'n_estimators': 96. El accuracy obtenido es de 0.886 vs el obtenido anteriormente de 0.84 con el modelo sin calibrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de clasificación con la librería sklearn, presenten el acurracy del modelo en el set de test y comenten sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8856812933025404"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 6\n",
    "from xgboost import XGBClassifier\n",
    "clfXGB = XGBClassifier()\n",
    "clfXGB.fit(X_train, y_train)\n",
    "\n",
    "predictXGB = clfXGB.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, predictXGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfXGB.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin calibrar los hiperparametros del XGBoost se obtiene un accuracy de 0.8856, parecido al obtenido con el Random Forest despues de calibrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para clasificación. Presenten el acurracy del modelo en el set de test, comenten sus resultados y análicen cómo cada parámetro afecta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_est...\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': array([0.1, 0.3, 0.5, 0.7, 0.9]),\n",
       "                         'eta': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                         'gamma': array([ 0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  1.2,  1.4,  1.6,  1.8,  2. ,\n",
       "        2.2,  2.4,  2.6,  2.8,  3. ,  3.2,  3.4,  3.6,  3.8,  4. ,  4.2,\n",
       "        4.4,  4.6,  4.8,  5. ,  5.2,  5.4,  5.6,  5.8,  6. ,  6.2,  6.4,\n",
       "        6.6,  6.8,  7. ,  7.2,  7.4,  7.6,  7.8,  8. ,  8.2,  8.4,  8.6,\n",
       "        8.8,  9. ,  9.2,  9.4,  9.6,  9.8, 10. ])})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NO CORRER - Se demora mucho. - Se realiza Gridsearch para buscar los parametros optimos.\n",
    "\n",
    "# Celda 7\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Learning rate\n",
    "\n",
    "learning_rate_range = np.arange(0.0,1,0.1)\n",
    "gamma_r = np.arange(0,10.2,0.2)\n",
    "colsample_bytree_r = np.arange(0.1, 1 , 0.2)\n",
    "\n",
    "\n",
    "clfXGB2=XGBClassifier()\n",
    "parameters = {'eta':learning_rate_range , 'gamma': gamma_r, 'colsample_bytree': colsample_bytree_r}\n",
    "XGB_calib = GridSearchCV(clfXGB2,parameters, n_jobs=-1)\n",
    "XGB_calib.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891454965357968"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictXGBcalib = XGB_calib.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, predictXGBcalib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5000000000000001,\n",
       " 'eta': 0.30000000000000004,\n",
       " 'gamma': 8.6,\n",
       " 'objective': 'binary:logistic'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = XGB_calib.best_params_\n",
    "\n",
    "params['objective'] = 'binary:logistic'\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentra que los mejores parametros son considerar 50% de las variables explicativas en cada arbol, learning rate de 0.3, y un gamma (disminucion minima en la perdidad para hacer una particion) del 8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:38:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8891454965357968"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se estima el modelo con los parametros optimos\n",
    "\n",
    "clfXGB = XGBClassifier( **params )\n",
    "clfXGB.fit(X_train, y_train)\n",
    "\n",
    "predictXGB = clfXGB.predict(X_test)\n",
    "\n",
    "accuracy_xgb_calib = metrics.accuracy_score(y_test, predictXGB)\n",
    "\n",
    "accuracy_xgb_calib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy estimado es un poco superior al encontrado con el modelo XGBoost sin calibrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 8\n",
    "\n",
    "modelos = ['DT_Manual' , 'Bagging_DT', 'Rand Forest', 'XGBoost' ]\n",
    "valores = [accuracy_manual, accuracy_bagging, accuracy_RF_calib, accuracy_xgb_calib ]\n",
    "xpos = np.arange(len(valores))\n",
    "\n",
    "plt.bar(modelos, valores)\n",
    "\n",
    "for i, v in enumerate(valores):\n",
    "    plt.text( x= xpos[i]-0.3, y=v, s = str(v)[0:6], verticalalignment='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los diferentes modelos tienen un desempeño muy parecido cuando comparamos el accuracy. El XGBoost tiene un Accuracy mayor de 0.8891 vs el arbol de decision manual, que tiene un accuracy de 0.8830. Si se tiene en cuenta que la ganancia de modelo de arbol de decision comparado con XGBoost es marginal, seria mejor escoger el modelo de arbol de decision por su facilidad de interpretacion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los diferentes modelo se encuentra que XGBoost es un modelo versatil ya que incluye varias mejoras como el tree prunning, imputacion de datos faltantes y cross validation, esto hace que el algoritmo tenga un buen desempeno incluso antes de calibrar, sin embargo se pierde la interpretabilidad. XGBoost es un modelo de Boosting, en el sentido que se realizan arboles de decision de manera secuencial, en la que cada arbol aprende de los errores de los arboles anteriores. \n",
    "Por el contrario, Random Forest genera arboles de manera paralela y al final se toma la votacion de los diferentes arboles. Aunque Random Forest no hace imputacion de valores faltantes, este algoritmo no se ve muy afectado por la existencia de los mismos. Random Forest genera variabilidad mediante bootstrap y mediante seleccion de variables explicativas de manera aleatoria para la construccion de cada arbol, lo que permite mejorar las predicciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
